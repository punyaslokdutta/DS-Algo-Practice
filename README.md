# DS-Algo-Practice
Data structures play a central role in modern computer science. You interact with data structures even more often than with algorithms
(think Google, your mail server, and even your network routers). In addition, data structures are essential building blocks in obtaining efficient algorithms. 


![dsalgo](https://user-images.githubusercontent.com/13198518/141805859-7b4f6415-3d84-47bc-9e6c-dbb613e13137.png)

TIME TRAVEL	We can remember the past efficiently (a technique called persistence), but in general it's difficult to change the past and see the outcomes on the present (retroactivity). So alas, Back To The Future isn't really possible.
GEOMETRY	When data has more than one dimension (e.g. maps, database tables).
DYNAMIC OPTIMALITY	Is there one binary search tree that's as good as all others? We still don't know, but we're close.
MEMORY HIERARCHY	Real computers have multiple levels of caches. We can optimize the number of cache misses, often without even knowing the size of the cache.
HASHING	Hashing is the most used data structure in computer science. And it's still an active area of research.
INTEGERS	Logarithmic time is too easy. By careful analysis of the information you're dealing with, you can often reduce the operation times substantially, sometimes even to constant. We will also cover lower bounds that illustrate when this is not possible.
DYNAMIC GRAPHS	A network link went down, or you just added or deleted a friend in a social network. We can still maintain essential information about the connectivity as it changes.
STRINGS	Searching for phrases in giant text (think Google or DNA).
SUCCINCT	Most “linear size” data structures you know are much larger than they need to be, often by an order of magnitude. Some data structures require almost no space beyond the raw data but are still fast (think heaps, but much cooler).

![ds algo2](https://user-images.githubusercontent.com/13198518/141806163-bedcdb69-af27-45ee-bab9-70ae3c85c283.png)
